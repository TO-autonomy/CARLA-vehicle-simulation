{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import Delaunay\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "from classes.CARLASemantics import SemanticColors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"generated_data\"\n",
    "LIDAR_DIR = \"LIDAR_TOP\"\n",
    "CAM_DIRS = [\"CAM_FRONT\", \"CAM_FRONT_LEFT\", \"CAM_FRONT_RIGHT\", \"CAM_BACK\", \"CAM_BACK_LEFT\", \"CAM_BACK_RIGHT\"]\n",
    "SEMANTIC_CAM_DIRS =  [\"SEMANTIC_CAM_FRONT\", \"SEMANTIC_CAM_FRONT_LEFT\", \"SEMANTIC_CAM_FRONT_RIGHT\", \"SEMANTIC_CAM_BACK\", \"SEMANTIC_CAM_BACK_LEFT\", \"SEMANTIC_CAM_BACK_RIGHT\"]\n",
    "DEPTH_CAM_DIRS = [\"DEPTH_CAM_FRONT\", \"DEPTH_CAM_FRONT_LEFT\", \"DEPTH_CAM_FRONT_RIGHT\", \"DEPTH_CAM_BACK\", \"DEPTH_CAM_BACK_LEFT\", \"DEPTH_CAM_BACK_RIGHT\"]\n",
    "DEPTH_BEV_DIR = \"DEPTH_BEV\"\n",
    "DEPTH_VISIBILITY_DIR = \"DEPTH_VISIBILITY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intrinsics file (list of sensor configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTRINSICS_FILEPATH = os.path.join(\"config\", \"nuscenes.intrinsics.json\")\n",
    "with open(INTRINSICS_FILEPATH, \"r\") as INTRINSICS_FILE:\n",
    "    INTRINSICS = json.load(INTRINSICS_FILE)\n",
    "\n",
    "print(INTRINSICS)\n",
    "\n",
    "INTRINSICS_MATRICES = dict()\n",
    "for SENSOR_NAME in INTRINSICS.keys():\n",
    "    if SENSOR_NAME in CAM_DIRS:\n",
    "        CAMERA_INTRINSICS = INTRINSICS[SENSOR_NAME]\n",
    "        fx = CAMERA_INTRINSICS.get('fx', CAMERA_INTRINSICS.get('fl'))\n",
    "        fy = CAMERA_INTRINSICS.get('fy', CAMERA_INTRINSICS.get('fl'))\n",
    "        w, h = CAMERA_INTRINSICS.get('w'), CAMERA_INTRINSICS.get('h')\n",
    "        ppx = w / 2\n",
    "        ppy = h / 2\n",
    "        d_type = CAMERA_INTRINSICS['disto_type']\n",
    "        D = np.array(CAMERA_INTRINSICS['disto'])\n",
    "\n",
    "        INTRINSICS_MATRICES[SENSOR_NAME] = np.array([[fx, 0, ppx, 0],\n",
    "                                                     [0, fy, ppy, 0],\n",
    "                                                     [0, 0, 1, 0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post processing constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_SIZE = 50\n",
    "GRID_RESOLUTION = 0.5\n",
    "MAX_SENSOR_SCAN_DISTANCE = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filesystem methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_files_in_dir(data_dir, string_to_find):\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if string_to_find in file:\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    os.remove(file_path)\n",
    "                    print(f\"Removed: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error removing {file_path}: {e}\")\n",
    "\n",
    "def get_all_filenames(dir, no_extension=False):\n",
    "    if no_extension:\n",
    "        return [filename.split(\".\")[0] for filename in os.listdir(dir)]\n",
    "    return [filename for filename in os.listdir(dir)]\n",
    "\n",
    "def clean_up_lidar_dir():\n",
    "    LIDAR_DIR_PATH = os.path.join(BASE_DIR, LIDAR_DIR)\n",
    "    remove_files_in_dir(LIDAR_DIR_PATH, \".bev.\")\n",
    "\n",
    "def clean_up_camera_dirs():\n",
    "    for CAM_DIR in CAM_DIRS:\n",
    "        CAM_DIR_PATH = os.path.join(BASE_DIR, CAM_DIR)\n",
    "        remove_files_in_dir(CAM_DIR_PATH, \".pointcloud.\")\n",
    "        remove_files_in_dir(CAM_DIR_PATH, \".visibility.\")\n",
    "        remove_files_in_dir(CAM_DIR_PATH, \".fov.\")\n",
    "\n",
    "def clean_up_depth_camera_dirs():\n",
    "    for DEPTH_CAM_DIR in DEPTH_CAM_DIRS:\n",
    "        DEPTH_CAM_DIR_PATH = os.path.join(BASE_DIR, DEPTH_CAM_DIR)\n",
    "        remove_files_in_dir(DEPTH_CAM_DIR_PATH, \".ply\")\n",
    "        remove_files_in_dir(DEPTH_CAM_DIR_PATH, \".fov.\")\n",
    "        remove_files_in_dir(DEPTH_CAM_DIR_PATH, \".visibility.\")\n",
    "\n",
    "def clean_up_depth_bev_dir():\n",
    "    DEPTH_BEV_DIR_PATH = os.path.join(BASE_DIR, DEPTH_BEV_DIR)\n",
    "    remove_files_in_dir(DEPTH_BEV_DIR_PATH, \".\")\n",
    "        \n",
    "def save_point_cloud(file_path, point_cloud):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    if type(point_cloud) is o3d.geometry.PointCloud:\n",
    "        o3d.io.write_point_cloud(file_path, point_cloud)\n",
    "        return\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(point_cloud)\n",
    "    o3d.io.write_point_cloud(file_path, pcd)\n",
    "\n",
    "def read_point_cloud(file_path):\n",
    "    point_cloud = o3d.io.read_point_cloud(file_path)\n",
    "    return np.asarray(point_cloud.points)\n",
    "\n",
    "def save_image(file_path, mask):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    cv2.imwrite(file_path, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground Truth from depth camera point clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depth image parsing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_depth_map_from_image(image):\n",
    "    B = image[:, :, 0]\n",
    "    G = image[:, :, 1]\n",
    "    R = image[:, :, 2]\n",
    "    normalized = (G + B * 256 + R * 256 * 256) / (256 * 256 - 1)\n",
    "    depth_map = normalized * 1000\n",
    "    return depth_map\n",
    "\n",
    "def depth_image_to_point_cloud(depth_image, fov, max_distance=None):\n",
    "    \n",
    "    depth = calculate_depth_map_from_image(depth_image)\n",
    "    if max_distance != None:\n",
    "        depth[depth > max_distance] = 0.0 \n",
    "    height, width = depth_image.shape[:2]\n",
    "\n",
    "    # Create an intrinsic matrix from the camera parameters\n",
    "    fx = fy = 0.5 * width / np.tan(0.5 * np.radians(fov))\n",
    "    cx = width / 2.0\n",
    "    cy = height / 2.0\n",
    "\n",
    "    intrinsic = o3d.camera.PinholeCameraIntrinsic(width, height, fx, fy, cx, cy)\n",
    "\n",
    "    depth_o3d = o3d.geometry.Image(depth.astype(np.float32))\n",
    "    \n",
    "    pcd = o3d.geometry.PointCloud.create_from_depth_image(depth_o3d, intrinsic) #, depth_scale=1.0, depth_trunc=float(max_distance))\n",
    "    points = np.asarray(pcd.points)\n",
    "    swapped_points = points[:, [2, 0, 1]]\n",
    "    swapped_points[:, 2] = swapped_points[:, 2] * (-1)\n",
    "    pcd.points = o3d.utility.Vector3dVector(swapped_points)\n",
    "    \n",
    "    return pcd\n",
    "\n",
    "def create_color_mask(image, colors, inverted=False):\n",
    "    mask = np.full((image.shape[0], image.shape[1]), 0, dtype=np.uint8)\n",
    "    \n",
    "    B, G, R = image[:, :, 0], image[:, :, 1], image[:, :, 2]\n",
    "    # Iterate through the list of colors\n",
    "    for color in colors:\n",
    "        # Extract color channels\n",
    "        r, g, b = color\n",
    "        # Create boolean masks for each channel comparison\n",
    "        r_mask = R == r\n",
    "        g_mask = G == g\n",
    "        b_mask = B == b\n",
    "        # Combine channel masks to get the final color mask\n",
    "        color_mask = r_mask & g_mask & b_mask\n",
    "        # Update the overall mask where any color matches\n",
    "        mask[color_mask] = 255\n",
    "\n",
    "    if inverted:\n",
    "        mask = np.where(mask == 0, 255, 0).astype(np.uint8)\n",
    "        return mask\n",
    "    return mask\n",
    "\n",
    "def mask_image(image, image_mask):\n",
    "    masked = np.copy(image)\n",
    "    masked[image_mask == 0] = 0\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create FOV and visibility masks from depth images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask(grid, camera_matrix, T, image_size):\n",
    "    homogeneous_grid = np.vstack([grid[i].flatten() for i in range(3)] + [np.ones(grid[0].size)])\n",
    "    tfd_points = np.dot(T, homogeneous_grid)\n",
    "    tfd_points = np.dot(camera_matrix, tfd_points)\n",
    "    mask_x = tfd_points[0] < 0 # Exclude points behind the camera (x-axis is forward)\n",
    "    tfd_points[0][tfd_points[0] == 0] = np.nan  # Replace zeros with NaN to avoid division by zero\n",
    "    projected_points = tfd_points / tfd_points[0]\n",
    "    mask = ((0 <= projected_points[1]) & (projected_points[1] < image_size[0]) &\n",
    "            (0 <= projected_points[2]) & (projected_points[2] < image_size[1]) &\n",
    "            mask_x)\n",
    "    return mask.reshape(grid[0].shape)\n",
    "\n",
    "def get_camera_fov_masks(camera_calibs, lidar_to_cam_tf_list=[], grid_size_m=50, resolution=0.5):\n",
    "    whole_mask = np.zeros((int(grid_size_m / resolution), int(grid_size_m / resolution)))\n",
    "    x, y = np.meshgrid(np.arange(whole_mask.shape[1]), np.arange(whole_mask.shape[0]))\n",
    "    x = x - whole_mask.shape[1] / 2\n",
    "    y = y - whole_mask.shape[0] / 2\n",
    "    z = np.zeros_like(x)\n",
    "    bev_grid = np.array([x, y, z])\n",
    "    bev_grid = np.expand_dims(bev_grid, axis=-1)\n",
    "\n",
    "    cam_masks = {}\n",
    "\n",
    "    for i, (camera, calib) in enumerate(camera_calibs.items()):\n",
    "        intrinsic = calib['K']\n",
    "\n",
    "        w, h = calib['w'], calib['h']\n",
    "\n",
    "        if lidar_to_cam_tf_list:\n",
    "            cam_T_lidar = np.linalg.inv(lidar_to_cam_tf_list[i])\n",
    "            \n",
    "        else:\n",
    "            cam_T_lidar = np.linalg.inv(calib['T'])\n",
    "\n",
    "        mask = generate_mask(bev_grid, camera_matrix=intrinsic, T=cam_T_lidar, image_size=(w, h))\n",
    "        visible_bev = np.array([dim[mask] for dim in bev_grid])\n",
    "\n",
    "        mask_ref = visible_bev[:2]\n",
    "        cam_mask = np.zeros_like(mask)\n",
    "\n",
    "        mask_ref[1] += mask.shape[1] / 2\n",
    "        mask_ref[0] += mask.shape[0] / 2\n",
    "        mask_ref = np.round(mask_ref).astype(int)\n",
    "\n",
    "        cam_mask[mask_ref[1], mask_ref[0]] = 1\n",
    "        cam_mask = cam_mask.squeeze(-1)\n",
    "\n",
    "        cam_masks[camera] = cam_mask\n",
    "    return cam_masks\n",
    "\n",
    "def get_fov_mask(image, transformation_matrix, camera_intrinsics_matrix):\n",
    "    # Example camera calibration data for two cameras\n",
    "    camera_calibs = {\n",
    "        'camera': {\n",
    "            'K': camera_intrinsics_matrix,\n",
    "            'w': image.shape[1],  # Image width\n",
    "            'h': image.shape[0],  # Image height\n",
    "            'T': transformation_matrix\n",
    "        }\n",
    "    }\n",
    "    # Generate the camera FOV masks\n",
    "    cam_masks = get_camera_fov_masks(camera_calibs, grid_size_m=GRID_SIZE, resolution=GRID_RESOLUTION)\n",
    "    fov_mask = np.asarray(cam_masks[\"camera\"], dtype=np.uint8) * 255\n",
    "    \n",
    "    return fov_mask\n",
    "\n",
    "def extract_XY_translation_from_transform(transform_matrix):\n",
    "    return transform_matrix[:, 3][:2]\n",
    "\n",
    "def extract_yaw_from_transform(transform_matrix):\n",
    "    yaw_radians =  np.arctan2(transform_matrix[1][0], transform_matrix[0][0])\n",
    "    return np.degrees(yaw_radians)\n",
    "\n",
    "def calculate_grid_coords(coords, grid_size, resolution):\n",
    "    grid_center = int(grid_size / resolution / 2), int(grid_size / resolution / 2)\n",
    "    grid_coords = int(grid_center[0] - coords[0] / resolution), int(grid_center[1] - coords[1] / resolution)\n",
    "    return grid_coords\n",
    "\n",
    "def calculate_relative_forward_direction(angle1, angle2):\n",
    "    angle = (angle1 - angle2) + 90\n",
    "    if angle < 0:\n",
    "        angle += 360\n",
    "    if angle > 360:\n",
    "        angle -= 360\n",
    "    return angle\n",
    "\n",
    "def is_angle_in_range_radians(angle, start_angle, end_angle):\n",
    "        if (angle < 0):\n",
    "            angle += 2 * np.pi\n",
    "\n",
    "        angle = angle % (2 * np.pi)\n",
    "        start_angle = start_angle % (2 * np.pi)\n",
    "        end_angle = end_angle % (2 * np.pi)\n",
    "        \n",
    "        if start_angle < end_angle:\n",
    "            # Normal case where the range does not cross 0 radians\n",
    "            return start_angle <= angle <= end_angle\n",
    "        else:\n",
    "            # Case where the range crosses 0 radians\n",
    "            return angle >= start_angle or angle <= end_angle\n",
    "\n",
    "def create_fov_mask(grid_size, grid_resolution, sensor_coords, sensor_direction, fov_degrees):    \n",
    "    # Create an empty mask\n",
    "    mask = np.zeros((int(grid_size / grid_resolution), int(grid_size / grid_resolution)), dtype=np.uint8)\n",
    "    \n",
    "    # Convert the FOV and direction to radians\n",
    "    sensor_direction_rad = np.deg2rad(sensor_direction)\n",
    "    fov_rad = np.deg2rad(fov_degrees)\n",
    "    \n",
    "    # Calculate the angle range for the FOV\n",
    "    fov_start = sensor_direction_rad - fov_rad / 2\n",
    "    fov_end = sensor_direction_rad + fov_rad / 2\n",
    "    \n",
    "    # Calculate the position of the sensor\n",
    "    y0, x0 = sensor_coords\n",
    "    \n",
    "    # Iterate over each point in the grid\n",
    "    for y in range(mask.shape[0]):\n",
    "        for x in range(mask.shape[1]):\n",
    "            # Calculate the angle from the sensor to this point\n",
    "            dy = y - y0\n",
    "            dx = x - x0\n",
    "\n",
    "            angle = np.arctan2(dy, dx)\n",
    "\n",
    "            # Check if the angle is within the FOV\n",
    "            if is_angle_in_range_radians(angle, fov_start, fov_end):\n",
    "                mask[y, x] = 255\n",
    "    \n",
    "    \n",
    "    return mask\n",
    "\n",
    "clean_up_depth_camera_dirs()\n",
    "\n",
    "for (SEM_DIR, DEPTH_DIR, CAM_DIR) in zip(SEMANTIC_CAM_DIRS, DEPTH_CAM_DIRS, CAM_DIRS):\n",
    "    for filename in os.listdir(os.path.join(BASE_DIR, DEPTH_DIR)):\n",
    "        if filename.endswith('.png'):\n",
    "            depth_image_path = os.path.join(BASE_DIR, DEPTH_DIR, filename)\n",
    "            depth_image = cv2.imread(depth_image_path)\n",
    "            depth_camera_fov = INTRINSICS.get(CAM_DIR).get(\"fov\")\n",
    "            depth_image_point_cloud = depth_image_to_point_cloud(depth_image, fov=depth_camera_fov, max_distance=MAX_SENSOR_SCAN_DISTANCE)\n",
    "            \n",
    "            depth_camera_transform_path = os.path.join(BASE_DIR, DEPTH_DIR, filename.replace(\".png\", \".npy\"))\n",
    "            depth_camera_transform = np.load(depth_camera_transform_path)\n",
    "            lidar_transform = np.load(os.path.join(BASE_DIR, LIDAR_DIR, filename.replace(\".png\", \".npy\")))\n",
    "            lidar_transform_inv = np.linalg.inv(lidar_transform)\n",
    "            combined_transform = np.dot(lidar_transform_inv, depth_camera_transform)\n",
    "            depth_image_point_cloud.transform(combined_transform)\n",
    "\n",
    "            depth_image_point_cloud_path = os.path.join(BASE_DIR, DEPTH_DIR, filename.replace(\".png\", \".ply\"))\n",
    "            print(f\"Added: {depth_image_point_cloud_path}\")\n",
    "            save_point_cloud(depth_image_point_cloud_path, depth_image_point_cloud)\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            fov_mask_image = get_fov_mask(\n",
    "                depth_image,\n",
    "                combined_transform,\n",
    "                INTRINSICS_MATRICES[CAM_DIR] \n",
    "            )\n",
    "            \"\"\"\n",
    "            lidar_coords = extract_XY_translation_from_transform(lidar_transform)\n",
    "            lidar_forward_direction = extract_yaw_from_transform(lidar_transform)\n",
    "            camera_coords = extract_XY_translation_from_transform(depth_camera_transform)\n",
    "            camera_forward_direction = extract_yaw_from_transform(depth_camera_transform)\n",
    "            relative_coords = lidar_coords - camera_coords\n",
    "            camera_grid_coords = calculate_grid_coords(relative_coords, GRID_SIZE, GRID_RESOLUTION)\n",
    "            camera_grid_forward_direction = calculate_relative_forward_direction(lidar_forward_direction, camera_forward_direction)\n",
    "            camera_fov = INTRINSICS.get(CAM_DIR).get(\"fov\")\n",
    "            fov_mask = create_fov_mask(GRID_SIZE, GRID_RESOLUTION, camera_grid_coords, camera_grid_forward_direction, camera_fov)\n",
    "            fov_mask_path = os.path.join(BASE_DIR, DEPTH_DIR, filename.replace(\".png\", \".fov.png\"))\n",
    "            print(f\"Added: {fov_mask_path}\")\n",
    "            save_image(fov_mask_path, fov_mask)\n",
    "            \n",
    "            def rasterize_to_bev(points, resolution=0.5, grid_size=25):\n",
    "                bev_map = np.zeros((int(grid_size / resolution), int(grid_size / resolution)))\n",
    "                # Converting to grid coordinates\n",
    "                grid_coords = np.floor(points[:, :2] / resolution).astype(np.int32) + int(grid_size // (2 * resolution))\n",
    "                \n",
    "                # Ensure that grid coordinates are within the bounds of the BEV map\n",
    "                valid_points = (grid_coords[:, 0] >= 0) & (grid_coords[:, 0] < bev_map.shape[0]) & \\\n",
    "                            (grid_coords[:, 1] >= 0) & (grid_coords[:, 1] < bev_map.shape[1])\n",
    "                # Populate the BEV map with occupancy\n",
    "                bev_map[grid_coords[valid_points, 0], grid_coords[valid_points, 1]] = 255\n",
    "                return bev_map\n",
    "\n",
    "            visibility_mask = rasterize_to_bev(np.asarray(depth_image_point_cloud.points), resolution=GRID_RESOLUTION, grid_size=GRID_SIZE)\n",
    "            visibility_mask_path = os.path.join(BASE_DIR, DEPTH_DIR, filename.replace(\".png\", \".visibility.png\"))\n",
    "            print(f\"Added: {visibility_mask_path}\")\n",
    "            save_image(visibility_mask_path, visibility_mask)\n",
    "\n",
    "timestamps = get_all_filenames(os.path.join(BASE_DIR, DEPTH_CAM_DIRS[0]), no_extension=True)\n",
    "for timestamp in timestamps:\n",
    "    cumulative_visibility_mask = np.zeros((int(GRID_SIZE / GRID_RESOLUTION), int(GRID_SIZE / GRID_RESOLUTION)))\n",
    "    for (SEM_DIR, DEPTH_DIR, CAM_DIR) in zip(SEMANTIC_CAM_DIRS, DEPTH_CAM_DIRS, CAM_DIRS):\n",
    "        depth_image_path = os.path.join(BASE_DIR, DEPTH_DIR, f\"{timestamp}.visibility.png\")\n",
    "        visibility_mask = cv2.imread(depth_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        cumulative_visibility_mask[visibility_mask > 0] = 255\n",
    "    cumulative_visibility_mask_path = os.path.join(BASE_DIR, DEPTH_VISIBILITY_DIR, f\"{timestamp}.bev.png\")\n",
    "    save_image(cumulative_visibility_mask_path, cumulative_visibility_mask)\n",
    "    print(f\"Added: {cumulative_visibility_mask_path}\")\n",
    "\n",
    "    lidar_transform_path = os.path.join(BASE_DIR, LIDAR_DIR, f\"{timestamp}.npy\")\n",
    "    lidar_transform = np.load(lidar_transform_path)\n",
    "    transformation_file_path = os.path.join(BASE_DIR, DEPTH_VISIBILITY_DIR, f\"{timestamp}.npy\")\n",
    "    np.save(transformation_file_path, lidar_transform)\n",
    "    print(f\"Added: {transformation_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create point clouds and occupancy maps from depth images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_filenames(dir, no_extension=False):\n",
    "    if no_extension:\n",
    "        return [filename.split(\".\")[0] for filename in os.listdir(dir)]\n",
    "    return [filename for filename in os.listdir(dir)]\n",
    "\n",
    "def get_obstacle_point_cloud(depth_image, semantic_image, fov):\n",
    "    obstacles_mask = create_color_mask(\n",
    "        semantic_image, \n",
    "        colors=[\n",
    "            SemanticColors.ROADLINE.value, SemanticColors.ROAD.value, SemanticColors.SIDEWALK.value,\n",
    "            SemanticColors.GROUND.value, SemanticColors.WATER.value, SemanticColors.TERRAIN.value,\n",
    "            SemanticColors.SKY.value\n",
    "        ],\n",
    "        inverted=True\n",
    "    )\n",
    "    obstacles_depth_image = mask_image(depth_image, obstacles_mask)\n",
    "\n",
    "    ground_mask = create_color_mask(semantic_image, colors=[\n",
    "        SemanticColors.ROADLINE.value, SemanticColors.ROAD.value, SemanticColors.SIDEWALK.value,\n",
    "        SemanticColors.GROUND.value, SemanticColors.WATER.value, SemanticColors.TERRAIN.value\n",
    "    ])\n",
    "    ground_depth_image = mask_image(depth_image, ground_mask)\n",
    "\n",
    "    obstacles_point_cloud = depth_image_to_point_cloud(obstacles_depth_image, fov=fov, max_distance=MAX_SENSOR_SCAN_DISTANCE)\n",
    "    ground_point_cloud = depth_image_to_point_cloud(ground_depth_image, fov=fov, max_distance=MAX_SENSOR_SCAN_DISTANCE)\n",
    "\n",
    "    def gen_mesh(pcd): \n",
    "        try:\n",
    "            points = np.asarray(pcd.points)\n",
    "        except:\n",
    "            points = pcd\n",
    "        tri = Delaunay(points[:, :2])  # We only use the X and Y coordinates\n",
    "        mesh = o3d.geometry.TriangleMesh()\n",
    "        mesh.vertices = o3d.utility.Vector3dVector(points)\n",
    "        mesh.triangles = o3d.utility.Vector3iVector(tri.simplices)\n",
    "        return mesh\n",
    "    \n",
    "    def mesh_to_cloud_signed_distances(o3d_mesh: o3d.t.geometry.TriangleMesh, cloud: o3d.t.geometry.PointCloud) -> np.ndarray:\n",
    "        scene = o3d.t.geometry.RaycastingScene()\n",
    "        _ = scene.add_triangles(o3d_mesh)\n",
    "        sdf = scene.compute_signed_distance(cloud.point.positions)\n",
    "        return sdf.numpy()\n",
    "\n",
    "    def filter_points_far_from_mesh(pcd, distances, t1, t2):\n",
    "        indices1 = np.where((distances > t1) & (distances <= t2))[0]\n",
    "        indices2 = np.where(distances < t1)[0]\n",
    "        objects = pcd.select_by_index(indices1)\n",
    "        ground = pcd.select_by_index(indices2)\n",
    "        return objects, ground\n",
    "\n",
    "    def remove_points_far_from_mesh(pcd, mesh, height_range=(0.4, 2)):\n",
    "        mesh_t = o3d.t.geometry.TriangleMesh.from_legacy(mesh)\n",
    "        tpcd = o3d.t.geometry.PointCloud.from_legacy(pcd)\n",
    "        sdf = mesh_to_cloud_signed_distances(mesh_t, tpcd)\n",
    "        sdf = np.abs(sdf)\n",
    "        obstacles, ground = filter_points_far_from_mesh(pcd, sdf, *height_range)\n",
    "        return obstacles, ground\n",
    "    try:\n",
    "        ground_mesh = gen_mesh(ground_point_cloud)\n",
    "        obstacles_point_cloud, ground_point_cloud = remove_points_far_from_mesh(obstacles_point_cloud, ground_mesh, height_range=(0.2, 3))\n",
    "    except:\n",
    "        pass\n",
    "    return obstacles_point_cloud\n",
    "\n",
    "clean_up_depth_bev_dir()\n",
    "\n",
    "timestamps = get_all_filenames(os.path.join(BASE_DIR, DEPTH_CAM_DIRS[0]), no_extension=True)\n",
    "for timestamp in timestamps:\n",
    "    cumulative_point_cloud = o3d.geometry.PointCloud()\n",
    "    for (SEM_DIR, DEPTH_DIR, CAM_DIR) in zip(SEMANTIC_CAM_DIRS, DEPTH_CAM_DIRS, CAM_DIRS):\n",
    "        depth_image_path = os.path.join(BASE_DIR, DEPTH_DIR, f\"{timestamp}.png\")\n",
    "        depth_image = cv2.imread(depth_image_path)\n",
    "        depth_camera_fov = INTRINSICS.get(CAM_DIR).get(\"fov\")\n",
    "        semantic_image_path = os.path.join(BASE_DIR, SEM_DIR, f\"{timestamp}.png\")\n",
    "        semantic_image = cv2.imread(semantic_image_path)\n",
    "        depth_point_cloud = get_obstacle_point_cloud(depth_image, semantic_image, depth_camera_fov)\n",
    "        depth_camera_transform_path = os.path.join(BASE_DIR, DEPTH_DIR, f\"{timestamp}.npy\")\n",
    "        depth_camera_transform = np.load(depth_camera_transform_path)\n",
    "        depth_point_cloud.transform(depth_camera_transform)\n",
    "        cumulative_point_cloud.points.extend(depth_point_cloud.points)\n",
    "    reference_transform_matrix = np.load(os.path.join(BASE_DIR, LIDAR_DIR, f\"{timestamp}.npy\"))\n",
    "    cumulative_point_cloud.transform(np.linalg.inv(reference_transform_matrix))\n",
    "    cumulative_point_cloud_file_path = os.path.join(BASE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.ply\")\n",
    "    save_point_cloud(cumulative_point_cloud_file_path, cumulative_point_cloud)\n",
    "    print(f\"Added: {cumulative_point_cloud_file_path}\")\n",
    "\n",
    "    transformation_file_path = os.path.join(BASE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.npy\")\n",
    "    np.save(transformation_file_path, reference_transform_matrix)\n",
    "    print(f\"Added: {transformation_file_path}\")\n",
    "\n",
    "    occupancy_image = rasterize_to_bev(np.asarray(cumulative_point_cloud.points), resolution=GRID_RESOLUTION, grid_size=GRID_SIZE)\n",
    "    occupancy_image_path = os.path.join(BASE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.bev.png\")\n",
    "    save_image(occupancy_image_path, occupancy_image)\n",
    "    print(f\"Added: {occupancy_image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground Truth from semantic LIDAR point clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create occupancy maps from LIDAR point clouds & FOV and visibility masks for camera sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rasterize_to_bev(points, resolution=0.5, grid_size=25):\n",
    "    bev_map = np.zeros((int(grid_size / resolution), int(grid_size / resolution)))\n",
    "    # Converting to grid coordinates\n",
    "    grid_coords = np.floor(points[:, :2] / resolution).astype(np.int32) + int(grid_size // (2 * resolution))\n",
    "    \n",
    "    # Ensure that grid coordinates are within the bounds of the BEV map\n",
    "    valid_points = (grid_coords[:, 0] >= 0) & (grid_coords[:, 0] < bev_map.shape[0]) & \\\n",
    "                   (grid_coords[:, 1] >= 0) & (grid_coords[:, 1] < bev_map.shape[1])\n",
    "    # Populate the BEV map with occupancy\n",
    "    bev_map[grid_coords[valid_points, 0], grid_coords[valid_points, 1]] = 255\n",
    "    return bev_map\n",
    "\n",
    "clean_up_lidar_dir()\n",
    "\n",
    "for filename in os.listdir(os.path.join(BASE_DIR, LIDAR_DIR)):\n",
    "    if filename.endswith('.ply'):\n",
    "        point_cloud_file_path = os.path.join(BASE_DIR, LIDAR_DIR, filename)\n",
    "        point_cloud = read_point_cloud(point_cloud_file_path)\n",
    "        bev_rasterized_image = rasterize_to_bev(point_cloud, resolution=GRID_RESOLUTION, grid_size=GRID_SIZE)\n",
    "        bev_file_path = os.path.join(BASE_DIR, LIDAR_DIR, filename.replace(\".ply\", \".bev.mask.png\"))\n",
    "        print(f\"Added: {bev_file_path}\")\n",
    "        save_image(bev_file_path, bev_rasterized_image)\n",
    "\n",
    "def extract_XY_translation_from_transform(transform_matrix):\n",
    "    return transform_matrix[:, 3][:2]\n",
    "\n",
    "def extract_yaw_from_transform(transform_matrix):\n",
    "    yaw_radians =  np.arctan2(transform_matrix[1][0], transform_matrix[0][0])\n",
    "    return np.degrees(yaw_radians)\n",
    "\n",
    "def calculate_grid_coords(coords, grid_size, resolution=0.5):\n",
    "    grid_center = (grid_size // 2, grid_size // 2)\n",
    "    return (int(grid_center[0] - coords[0]), int(grid_center[1] - coords[1]))\n",
    "\n",
    "def calculate_relative_forward_direction(angle1, angle2):\n",
    "    angle = (angle1 - angle2) + 90\n",
    "    if angle < 0:\n",
    "        angle += 360\n",
    "    if angle > 360:\n",
    "        angle -= 360\n",
    "    return angle\n",
    "\n",
    "def is_angle_in_range_radians(angle, start_angle, end_angle):\n",
    "        angle = angle % (2 * np.pi)\n",
    "        start_angle = start_angle % (2 * np.pi)\n",
    "        end_angle = end_angle % (2 * np.pi)\n",
    "        \n",
    "        if start_angle < end_angle:\n",
    "            # Normal case where the range does not cross 0 radians\n",
    "            return start_angle <= angle <= end_angle\n",
    "        else:\n",
    "            # Case where the range crosses 0 radians\n",
    "            return angle >= start_angle or angle <= end_angle\n",
    "\n",
    "def create_fov_mask(grid_size, sensor_coords, sensor_direction, fov_degrees):    \n",
    "    # Create an empty mask\n",
    "    mask = np.zeros((grid_size, grid_size), dtype=np.uint8)\n",
    "    \n",
    "    # Convert the FOV and direction to radians\n",
    "    sensor_direction_rad = np.deg2rad(sensor_direction)\n",
    "    fov_rad = np.deg2rad(fov_degrees)\n",
    "    \n",
    "    # Calculate the angle range for the FOV\n",
    "    fov_start = sensor_direction_rad - fov_rad / 2\n",
    "    fov_end = sensor_direction_rad + fov_rad / 2\n",
    "    \n",
    "    # Calculate the position of the sensor\n",
    "    y0, x0 = sensor_coords\n",
    "    \n",
    "    # Iterate over each point in the grid\n",
    "    for y in range(grid_size):\n",
    "        for x in range(grid_size):\n",
    "            # Calculate the angle from the sensor to this point\n",
    "            dy = y - y0\n",
    "            dx = x - x0\n",
    "\n",
    "            angle = np.arctan2(dy, dx)\n",
    "            if (angle < 0):\n",
    "                angle += 2 * np.pi\n",
    "\n",
    "            # Check if the angle is within the FOV\n",
    "            if is_angle_in_range_radians(angle, fov_start, fov_end):\n",
    "                mask[y, x] = 255\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def create_visibility_mask(world_grid, fov_grid, sensor_coords):\n",
    "    \n",
    "    def find_path(start_point, end_point):\n",
    "        # https://en.wikipedia.org/wiki/Bresenham%27s_line_algorithm\n",
    "        path = []\n",
    "        \n",
    "        x0, y0 = start_point\n",
    "        x1, y1 = end_point\n",
    "        dx = abs(x1 - x0)\n",
    "        dy = abs(y1 - y0)\n",
    "        sx = 1 if x0 < x1 else -1\n",
    "        sy = 1 if y0 < y1 else -1\n",
    "        err = dx - dy\n",
    "        \n",
    "        while True:\n",
    "            path.append((x0, y0))\n",
    "            if x0 == x1 and y0 == y1:\n",
    "                break\n",
    "            e2 = 2 * err\n",
    "            if e2 > -dy:\n",
    "                err -= dy\n",
    "                x0 += sx\n",
    "            if e2 < dx:\n",
    "                err += dx\n",
    "                y0 += sy\n",
    "        \n",
    "        return path\n",
    "\n",
    "    def remove_obstructed_sections(world, path, visibility_mask):\n",
    "        obstruction_detected = False\n",
    "        for x, y in path:\n",
    "            if world[y][x] == 255:\n",
    "                obstruction_detected = True\n",
    "            if obstruction_detected:\n",
    "                visibility_mask[y][x] = 0\n",
    "\n",
    "    def get_fov_coordinates(array):\n",
    "        return np.argwhere(array == 255)\n",
    "\n",
    "    visibility_mask = np.copy(fov_grid)\n",
    "    all_fov_coords = get_fov_coordinates(fov_grid)\n",
    "    \n",
    "    for (y, x) in all_fov_coords:\n",
    "        path = find_path(sensor_coords, (x, y))\n",
    "        remove_obstructed_sections(world_grid, path, visibility_mask)\n",
    "    return visibility_mask\n",
    "\n",
    "\n",
    "clean_up_camera_dirs()\n",
    "\n",
    "for filename in os.listdir(os.path.join(BASE_DIR, LIDAR_DIR)): \n",
    "    if filename.endswith('.npy'):\n",
    "        lidar_npy_file = os.path.join(BASE_DIR, LIDAR_DIR, filename)\n",
    "        lidar_transform_matrix = np.load(lidar_npy_file)\n",
    "        lidar_coords = extract_XY_translation_from_transform(lidar_transform_matrix)\n",
    "        lidar_forward_direction = extract_yaw_from_transform(lidar_transform_matrix)\n",
    "        lidar_bev_file = os.path.join(BASE_DIR, LIDAR_DIR, filename.replace('.npy', '.bev.mask.png'))\n",
    "        lidar_bev_mask = cv2.imread(lidar_bev_file, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        for CAM_DIR in CAM_DIRS:\n",
    "            camera_npy_file = os.path.join(BASE_DIR, CAM_DIR, filename)\n",
    "            camera_transform_matrix = np.load(camera_npy_file)\n",
    "            camera_coords = extract_XY_translation_from_transform(camera_transform_matrix)\n",
    "            camera_forward_direction = extract_yaw_from_transform(camera_transform_matrix)  # degrees\n",
    "            \n",
    "            relative_coords = lidar_coords - camera_coords\n",
    "            camera_grid_coords = calculate_grid_coords(relative_coords, GRID_SIZE)\n",
    "            camera_grid_forward_direction = calculate_relative_forward_direction(lidar_forward_direction, camera_forward_direction)\n",
    "\n",
    "            camera_fov = INTRINSICS.get(CAM_DIR).get(\"fov\")\n",
    "            fov_mask = create_fov_mask(GRID_SIZE, camera_grid_coords, camera_grid_forward_direction, camera_fov)\n",
    "            fov_mask_file_path = os.path.join(BASE_DIR, CAM_DIR, filename.replace('.npy', '.fov.mask.png'))\n",
    "            print(f\"Added: {fov_mask_file_path}\")\n",
    "            save_image(fov_mask_file_path, fov_mask)\n",
    "\n",
    "            visibility_mask = create_visibility_mask(lidar_bev_mask, fov_mask, camera_grid_coords)\n",
    "            visibility_mask_file_path = os.path.join(BASE_DIR, CAM_DIR, filename.replace('.npy', '.visibility.mask.png'))\n",
    "            print(f\"Added: {visibility_mask_file_path}\")\n",
    "            save_image(visibility_mask_file_path, visibility_mask)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export processed files to target directory (in suitable directory tree format for machine learning pipeline) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DIR = \"processed_data\"\n",
    "TARGET_CAM_DIRS = [\n",
    "    \"AGV_sensors_cameras_front_raw\", \"AGV_sensors_cameras_front_left_raw\", \"AGV_sensors_cameras_front_right_raw\", \n",
    "    \"AGV_sensors_cameras_back_raw\", \"AGV_sensors_cameras_back_left_raw\", \"AGV_sensors_cameras_back_right_raw\"\n",
    "]\n",
    "TARGET_LIDAR_DIR = \"AGV_sensors_lidar_top_raw\"\n",
    "TARGET_FOV_MASKS_DIR = \"fov_masks\"\n",
    "TARGET_BEVS_DIR = \"sdf\"\n",
    "TARGET_VISIBILITY_MASKS_DIR = \"visibility_masks\"\n",
    "TARGET_CUMULATIVE_MASKS_DIR = \"cumulative_masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_target_dir():\n",
    "    if not os.path.exists(TARGET_DIR):\n",
    "        return\n",
    "    for subdir in os.listdir(TARGET_DIR):\n",
    "        shutil.rmtree(os.path.join(TARGET_DIR, subdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files_with_extensions(source_dir, target_dir, extensions, exclude_strings=[]):\n",
    "    # Ensure the target directory exists\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "    \n",
    "    # Iterate through the files in the source directory\n",
    "    for root, _, files in os.walk(source_dir):\n",
    "        for file in files:\n",
    "            # Check if the file has one of the specified extensions\n",
    "            if any(file.endswith(ext) for ext in extensions):\n",
    "                # Check if the file name contains any of the exclude strings\n",
    "                if any(exclude_str in file for exclude_str in exclude_strings):\n",
    "                    print(f\"Excluded {file}\")\n",
    "                    continue\n",
    "                \n",
    "                # Construct full file paths\n",
    "                source_file = os.path.join(root, file)\n",
    "                target_file = os.path.join(target_dir, file)\n",
    "                \n",
    "                # Copy the file to the target directory\n",
    "                shutil.copy2(source_file, target_file)\n",
    "                print(f\"Copied {source_file} to {target_file}\")\n",
    "\n",
    "clean_up_target_dir()\n",
    "\n",
    "# Export RGB camera data\n",
    "source_dirs = [os.path.join(BASE_DIR, CAM_DIR) for CAM_DIR in CAM_DIRS]\n",
    "target_dirs = [os.path.join(TARGET_DIR, CAM_DIR) for CAM_DIR in TARGET_CAM_DIRS]\n",
    "for source_dir, target_dir in zip(source_dirs, target_dirs):\n",
    "    extensions = [\".png\", \".npy\"]\n",
    "    exclude_strings = [\"fov\", \"visibility\"]\n",
    "    copy_files_with_extensions(source_dir, target_dir, extensions, exclude_strings=exclude_strings)\n",
    "\n",
    "# Export lidar data\n",
    "source_dir = os.path.join(BASE_DIR, LIDAR_DIR)\n",
    "target_dir = os.path.join(TARGET_DIR, TARGET_LIDAR_DIR)\n",
    "extensions = [\".ply\", \".npy\"]\n",
    "copy_files_with_extensions(source_dir, target_dir, extensions)\n",
    "\n",
    "# Export FOV masks\n",
    "source_dirs = [os.path.join(BASE_DIR, DEPTH_CAM_DIR) for DEPTH_CAM_DIR in DEPTH_CAM_DIRS]\n",
    "target_dirs = [os.path.join(TARGET_DIR, TARGET_FOV_MASKS_DIR, CAM_DIR) for CAM_DIR in TARGET_CAM_DIRS]\n",
    "for source_dir, target_dir in zip(source_dirs, target_dirs):\n",
    "    extensions = [\".fov.png\", \".npy\"]\n",
    "    copy_files_with_extensions(source_dir, target_dir, extensions)\n",
    "\n",
    "# Export visibility masks\n",
    "source_dirs = [os.path.join(BASE_DIR, DEPTH_CAM_DIR) for DEPTH_CAM_DIR in DEPTH_CAM_DIRS]\n",
    "target_dirs = [os.path.join(TARGET_DIR, TARGET_VISIBILITY_MASKS_DIR, CAM_DIR) for CAM_DIR in TARGET_CAM_DIRS]\n",
    "for source_dir, target_dir in zip(source_dirs, target_dirs):\n",
    "    extensions = [\".visibility.png\", \".npy\"]\n",
    "    copy_files_with_extensions(source_dir, target_dir, extensions)\n",
    "\n",
    "# Export cumulative masks\n",
    "source_dir = os.path.join(BASE_DIR, DEPTH_VISIBILITY_DIR)\n",
    "target_dir = os.path.join(TARGET_DIR, TARGET_VISIBILITY_MASKS_DIR, TARGET_CUMULATIVE_MASKS_DIR)\n",
    "extensions = [\".bev.png\", \".npy\"]\n",
    "copy_files_with_extensions(source_dir, target_dir, extensions)\n",
    "\n",
    "# Export BEV masks\n",
    "source_dir = os.path.join(BASE_DIR, DEPTH_BEV_DIR)\n",
    "target_dir = os.path.join(TARGET_DIR, TARGET_BEVS_DIR)\n",
    "extensions = [\".png\", \".npy\"]\n",
    "copy_files_with_extensions(source_dir, target_dir, extensions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
