{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import queue\n",
    "import shutil \n",
    "import os\n",
    "import sys\n",
    "from enum import Enum\n",
    "from datetime import datetime\n",
    "\n",
    "import carla\n",
    "import numpy as np\n",
    "import urdf_parser_py.urdf as urdf\n",
    "from scipy.spatial.transform import Rotation   \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import open3d as o3d\n",
    "import cv2\n",
    "\n",
    "from classes.CARLASemantics import SemanticColors, SemanticTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    CARLA_ADDITIONAL_PYTHON_API_PATH = \"/home/erkoiv/Documents/CARLA_0.9.13/PythonAPI/carla\"\n",
    "    if CARLA_ADDITIONAL_PYTHON_API_PATH not in sys.path:\n",
    "        sys.path.append(CARLA_ADDITIONAL_PYTHON_API_PATH)\n",
    "    from agents.navigation.basic_agent import BasicAgent \n",
    "except Exception as error:\n",
    "    raise ImportError(f\"FATAL ERROR: Unable to import CARLA autonomous driving agent BasicAgent due to missing PythonAPI. The API is included in the simulator installation package (not included with \\\"import carla\\\"). Setup the CARLA simulator repository and add the correct PythonAPI path above. ({error})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to CARLA server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(10)\n",
    "world = client.get_world()\n",
    "map = world.get_map()\n",
    "\n",
    "blueprint_library = world.get_blueprint_library()\n",
    "spawn_points = world.get_map().get_spawn_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_world():\n",
    "    global world, map, blueprint_library, spawn_points, traffic_manager\n",
    "    world = client.reload_world()\n",
    "    map = world.get_map()\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    spawn_points = map.get_spawn_points()\n",
    "    traffic_manager = client.get_trafficmanager()\n",
    "\n",
    "def load_world(map_name=\"Town01\", timeout=10.0):\n",
    "    global world, map, blueprint_library, spawn_points, traffic_manager\n",
    "    client.set_timeout(timeout)\n",
    "    world = client.load_world(map_name)\n",
    "    map = world.get_map()\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    spawn_points = map.get_spawn_points()\n",
    "    traffic_manager = client.get_trafficmanager()\n",
    "\n",
    "load_world(map_name=\"Town03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarlaSyncMode(object):\n",
    "    \"\"\"\n",
    "        with CarlaSyncMode(world, sensors) as sync_mode:\n",
    "            while True:\n",
    "                data = sync_mode.tick(timeout=1.0)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, world, sensors, **kwargs):\n",
    "        self.world = world\n",
    "        self.sensors = sensors\n",
    "        self.frame = None\n",
    "        self.delta_seconds = 1.0 / kwargs.get('fps', 5)\n",
    "        self._queues = []\n",
    "        self._settings = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._settings = self.world.get_settings()\n",
    "        self.frame = self.world.apply_settings(carla.WorldSettings(\n",
    "            no_rendering_mode=False,\n",
    "            synchronous_mode=True,\n",
    "            fixed_delta_seconds=self.delta_seconds,\n",
    "            ))\n",
    "\n",
    "        def make_queue(register_event):\n",
    "            q = queue.Queue()\n",
    "            register_event(q.put)\n",
    "            self._queues.append(q)\n",
    "\n",
    "        make_queue(self.world.on_tick)\n",
    "        for sensor in self.sensors:\n",
    "            make_queue(sensor.listen)\n",
    "        return self\n",
    "\n",
    "    def tick(self, timeout=300):\n",
    "        self.frame = self.world.tick()\n",
    "        data = [self._retrieve_data(q, timeout) for q in self._queues]\n",
    "        assert all(x.frame == self.frame for x in data)\n",
    "        return data\n",
    "\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        self.world.apply_settings(self._settings)\n",
    "\n",
    "    def _retrieve_data(self, sensor_queue, timeout):\n",
    "        while True:\n",
    "            data = sensor_queue.get(timeout=timeout)\n",
    "            if data.frame == self.frame:\n",
    "                return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CARLA transformation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_transform(matrix):\n",
    "    # Ensure matrix is a NumPy array\n",
    "    if not isinstance(matrix, np.ndarray):\n",
    "        matrix = np.array(matrix)\n",
    "\n",
    "    # Extract translation\n",
    "    location = carla.Location(x=matrix[0, 3], y=(-matrix[1, 3]), z=matrix[2, 3])\n",
    "\n",
    "    roll, pitch, yaw = Rotation.from_matrix(matrix[:3, :3]).as_euler('xyz', degrees=True)\n",
    "    rotation = carla.Rotation(pitch=(-pitch), yaw=(-yaw), roll=roll)\n",
    "    \n",
    "    # Create and return carla.Transform\n",
    "    return carla.Transform(location, rotation)\n",
    "\n",
    "\n",
    "def build_transform_matrix(rotation, translation):\n",
    "    m = np.eye(4)\n",
    "    m[:3, :3] = rotation\n",
    "    m[:3, 3] = translation\n",
    "    return m\n",
    "\n",
    "\n",
    "def rotation_matrix(axis, angle):\n",
    "    \"\"\"\n",
    "    Create a rotation matrix for a given axis and angle.\n",
    "    \"\"\"\n",
    "    if axis == 'x':\n",
    "        return np.array([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, np.cos(angle), -np.sin(angle), 0],\n",
    "            [0, np.sin(angle), np.cos(angle), 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "    elif axis == 'y':\n",
    "        return np.array([\n",
    "            [np.cos(angle), 0, np.sin(angle), 0],\n",
    "            [0, 1, 0, 0],\n",
    "            [-np.sin(angle), 0, np.cos(angle), 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "    elif axis == 'z':\n",
    "        return np.array([\n",
    "            [np.cos(angle), -np.sin(angle), 0, 0],\n",
    "            [np.sin(angle), np.cos(angle), 0, 0],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "\n",
    "def reflection_matrix():\n",
    "    \"\"\"\n",
    "    Create a reflection matrix to flip the Y-axis.\n",
    "    \"\"\"\n",
    "    return np.array([\n",
    "        [1, 0, 0, 0],\n",
    "        [0, -1, 0, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "\n",
    "def transform_to_carla(sensor_type, transformation):\n",
    "    \"\"\"\n",
    "    Convert sensor transformation to CARLA format.\n",
    "    \"\"\"\n",
    "    sensor_type = sensor_type.lower().strip()\n",
    "    if sensor_type in ['camera', 'sensor.camera', 'sensor.camera.rgb', 'sensor.camera.semantic_segmentation', 'sensor.camera.depth']:\n",
    "        rotation1 = rotation_matrix('z', np.pi / 2)\n",
    "        rotation2 = rotation_matrix('y', -np.pi / 2)\n",
    "        rotation = np.dot(rotation1, rotation2)\n",
    "    elif sensor_type in ['lidar', 'sensor.lidar', 'sensor.lidar.ray_cast', 'sensor.lidar.ray_cast_semantic']:\n",
    "        rotation = rotation_matrix('z', np.pi / 2)\n",
    "    elif sensor_type in ['radar', 'sensor.other.radar']:\n",
    "        rotation = np.eye(4)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown sensor type\")\n",
    "    tf = np.dot(transformation, rotation)\n",
    "    return tf\n",
    "\n",
    "def transform_from_carla(sensor_type, transformation):\n",
    "    \"\"\"\n",
    "    Convert sensor transformation from CARLA format.\n",
    "    \"\"\"\n",
    "    sensor_type = sensor_type.lower().strip()\n",
    "    if sensor_type in ['camera', 'sensor.camera', 'sensor.camera.rgb', 'sensor.camera.semantic_segmentation', 'sensor.camera.depth']:\n",
    "        rotation1 = rotation_matrix('z', -np.pi / 2)\n",
    "        rotation2 = rotation_matrix('y', np.pi / 2)\n",
    "        rotation = np.dot(rotation2, rotation1)\n",
    "    elif sensor_type in ['lidar', 'sensor.lidar', 'sensor.lidar.ray_cast', 'sensor.lidar.ray_cast_semantic']:  \n",
    "        rotation = rotation_matrix('z', -np.pi / 2)\n",
    "    elif sensor_type in ['radar', 'sensor.other.radar']:\n",
    "        rotation = np.eye(4)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown sensor type\")\n",
    "    tf = np.dot(transformation, rotation)\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run path validation in CARLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "planned_path_json = dict()\n",
    "with open('config/town3.path.json') as path_file:\n",
    "    planned_path_json = json.load(path_file)\n",
    "planned_path = planned_path_json[\"route\"]\n",
    "\n",
    "def get_agent_path(coordinates):\n",
    "    path = []\n",
    "    for x, y, z in coordinates:\n",
    "        path.append(carla.Location(x=x, y=y, z=z))\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_path():\n",
    "    reload_world()\n",
    "\n",
    "    cv2.namedWindow(\"Press Q to stop simulation\")\n",
    "    cv2.imshow(\"Press Q to stop simulation\", np.zeros((1,1)))\n",
    "\n",
    "    blueprint_name = \"vehicle.micro.microlino\"\n",
    "    blueprint = blueprint_library.find(blueprint_name)\n",
    "    transform = spawn_points[0]\n",
    "    validation_vehicle = world.spawn_actor(blueprint, transform)\n",
    "\n",
    "    blueprint = blueprint_library.find(\"sensor.camera.rgb\")\n",
    "    blueprint.set_attribute('image_size_x', str(720))\n",
    "    blueprint.set_attribute('image_size_y', str(480))\n",
    "\n",
    "    transform_matrix = carla.Transform(carla.Location(x=1.7, y=0.0, z=1.5), carla.Rotation(roll=0, pitch=0, yaw=0)).get_matrix()\n",
    "    transform = matrix_to_transform(transform_matrix)\n",
    "    sensor = world.spawn_actor(blueprint, transform, attach_to=validation_vehicle)\n",
    "    validation_vehicle_control_agent = BasicAgent(validation_vehicle, target_speed=17)\n",
    "    validation_vehicle_control_agent.ignore_traffic_lights(active=True)\n",
    "    agent_path = get_agent_path(planned_path)\n",
    "    validation_vehicle_control_agent.set_destination(agent_path.pop(0))\n",
    "\n",
    "    visited_path = []\n",
    "    try:\n",
    "        with CarlaSyncMode(world, [sensor], fps=10) as sync_mode:\n",
    "            print(\"Driving to the start of the path...\")\n",
    "            while validation_vehicle_control_agent.done() is False:\n",
    "                if (cv2.waitKey(1) == ord('q')):\n",
    "                    break\n",
    "                \n",
    "                simulated_results = sync_mode.tick()[1:]\n",
    "                cam_sensor = simulated_results[0]\n",
    "                cam_sensor_image =  np.reshape(np.copy(cam_sensor.raw_data), (cam_sensor.height, cam_sensor.width, 4))\n",
    "                cv2.imshow(\"CAM_FRONT\", cam_sensor_image)\n",
    "\n",
    "                validation_vehicle.apply_control(validation_vehicle_control_agent.run_step())\n",
    "            print(\"Arrived at the start of the path!\")\n",
    "\n",
    "            print(\"Driving on path...\")\n",
    "            while True:\n",
    "                if (cv2.waitKey(1) == ord('q')):\n",
    "                    break\n",
    "\n",
    "                simulated_results = sync_mode.tick()[1:]\n",
    "                cam_sensor = simulated_results[0]\n",
    "                cam_sensor_image =  np.reshape(np.copy(cam_sensor.raw_data), (cam_sensor.height, cam_sensor.width, 4))\n",
    "                cv2.imshow(\"CAM_FRONT\", cam_sensor_image)\n",
    "                \n",
    "                if validation_vehicle_control_agent.done():\n",
    "                    print(f\"{datetime.now()} Checkpoint reached. Ego vehicle has reached {len(planned_path) - len(agent_path)}/{len(planned_path)} planned path points.\")\n",
    "                    visited_path.append(validation_vehicle.get_location())\n",
    "                    if (agent_path == []):\n",
    "                        break\n",
    "                    validation_vehicle_control_agent.set_destination(agent_path.pop(0))\n",
    "                validation_vehicle.apply_control(validation_vehicle_control_agent.run_step())\n",
    "            print(\"Drive finished!\")\n",
    "    except RuntimeError as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        cv2.destroyAllWindows()\n",
    "        validation_vehicle.destroy()\n",
    "\n",
    "    assert len(visited_path) == len(planned_path), \"Validation failed. The vehicle could not complete the planned path.\"\n",
    "\n",
    "skip_validation = True\n",
    "if not skip_validation:\n",
    "    validate_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare CARLA world for full simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add ego vehicle (with intrinsics and extrinsics from external configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class URDFParser:\n",
    "    def __init__(self, urdf_file):\n",
    "        self.urdf_file = urdf_file\n",
    "        self.robot = urdf.URDF.from_xml_file(urdf_file)\n",
    "        self.root = self.robot.get_root()\n",
    "\n",
    "    def compute_chain_transform(self, chain):\n",
    "        transform = np.eye(4)\n",
    "        \n",
    "        for joint in chain:\n",
    "            if joint not in self.robot.joint_map:\n",
    "                continue\n",
    "            \n",
    "            joint_info = self.robot.joint_map[joint]\n",
    "            rpy = joint_info.origin.rpy\n",
    "            xyz = joint_info.origin.xyz\n",
    "            rotation = Rotation.from_euler('xyz', rpy).as_matrix()\n",
    "            translation = np.array(xyz)\n",
    "            T = build_transform_matrix(rotation, translation)\n",
    "            transform = np.dot(transform, T)\n",
    "        \n",
    "        return transform\n",
    "\n",
    "    def get_T_from_to(self, start_frame, end_frame):\n",
    "        chain_1 = self.robot.get_chain(self.root, start_frame)\n",
    "        chain_2 = self.robot.get_chain(self.root, end_frame)\n",
    "        T1 = self.compute_chain_transform(chain_1)\n",
    "        T2 = self.compute_chain_transform(chain_2)\n",
    "        return np.dot(np.linalg.inv(T1), T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_world()\n",
    "\n",
    "blueprint_name = \"vehicle.micro.microlino\"\n",
    "blueprint = blueprint_library.find(blueprint_name)\n",
    "blueprint.set_attribute('role_name','ego')\n",
    "transform = spawn_points[0]\n",
    "vehicle = world.spawn_actor(blueprint, transform)\n",
    "vehicle_control_agent = BasicAgent(vehicle)\n",
    "vehicle_control_agent.ignore_traffic_lights(active=True)\n",
    "\n",
    "sensor_names = []\n",
    "sensor_types = []\n",
    "sensors = []\n",
    "\n",
    "axes = []\n",
    "\n",
    "extrinsics = URDFParser('config/nuscenes.extrinsics.urdf')\n",
    "intrinsics = dict()\n",
    "with open('config/nuscenes.intrinsics.json') as intrinsics_file:\n",
    "    intrinsics = json.load(intrinsics_file)\n",
    "\n",
    "for sensor_configuration in extrinsics.robot.links:\n",
    "    sensor_name = sensor_configuration.name\n",
    "\n",
    "    if \"CAM_\" in sensor_name:\n",
    "        blueprint_name = \"sensor.camera.rgb\"\n",
    "        sensor_type = blueprint_name\n",
    "        blueprint = blueprint_library.find(blueprint_name)\n",
    "        sensor_intrinsics = intrinsics.get(sensor_name, dict())\n",
    "\n",
    "        def calculate_fov(focal_length, image_width):\n",
    "            fov_radians = 2 * np.arctan(image_width / (2 * focal_length))\n",
    "            fov_degrees = np.degrees(fov_radians)\n",
    "            return fov_degrees\n",
    "        image_width = str(sensor_intrinsics.get(\"w\", 1600))\n",
    "        blueprint.set_attribute('image_size_x', image_width)\n",
    "        image_height = str(sensor_intrinsics.get(\"h\", 900))\n",
    "        blueprint.set_attribute('image_size_y', image_height)\n",
    "        focal_distance = float(sensor_intrinsics.get(\"fl\"))\n",
    "        field_of_view = str(calculate_fov(focal_distance, float(image_width)))\n",
    "        blueprint.set_attribute('fov', field_of_view)\n",
    "        \n",
    "        transform_matrix = extrinsics.compute_chain_transform(extrinsics.robot.get_chain(extrinsics.root, sensor_name))\n",
    "        transform_matrix = transform_to_carla(\"camera\", transform_matrix)\n",
    "        transform = matrix_to_transform(transform_matrix)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "        sensors.append(sensor)\n",
    "        sensor_types.append(sensor_type)\n",
    "        sensor_names.append(sensor_name)\n",
    "\n",
    "        ## Spawn additional DEPTH and SEMANTIC cams\n",
    "        \n",
    "        blueprint_name = \"sensor.camera.depth\"\n",
    "        sensor_type = blueprint_name\n",
    "        blueprint = blueprint_library.find(blueprint_name)\n",
    "        blueprint.set_attribute('image_size_x', image_width)\n",
    "        blueprint.set_attribute('image_size_y', image_height)\n",
    "        blueprint.set_attribute('fov', field_of_view)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "        sensors.append(sensor)\n",
    "        sensor_types.append(sensor_type)\n",
    "        sensor_names.append(f\"DEPTH_{sensor_name}\")\n",
    "\n",
    "        blueprint_name = \"sensor.camera.semantic_segmentation\"\n",
    "        sensor_type = blueprint_name\n",
    "        blueprint = blueprint_library.find(blueprint_name)\n",
    "        blueprint.set_attribute('image_size_x', image_width)\n",
    "        blueprint.set_attribute('image_size_y', image_height)\n",
    "        blueprint.set_attribute('fov', field_of_view)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "        sensors.append(sensor)\n",
    "        sensor_types.append(sensor_type)\n",
    "        sensor_names.append(f\"SEMANTIC_{sensor_name}\")\n",
    "\n",
    "    elif \"RADAR_\" in sensor_name:\n",
    "        blueprint_name = \"sensor.other.radar\"\n",
    "        sensor_type = blueprint_name\n",
    "        blueprint = blueprint_library.find(blueprint_name)     \n",
    "        blueprint.set_attribute('horizontal_fov', str(30.0)) \n",
    "        blueprint.set_attribute('vertical_fov', str(30.0)) \n",
    "        blueprint.set_attribute('points_per_second', str(1e5))\n",
    "        \n",
    "        transform_matrix = extrinsics.get_T_from_to(\"center\", sensor_name)\n",
    "        transform_matrix = transform_to_carla('radar', transform_matrix)\n",
    "        transform = matrix_to_transform(transform_matrix)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "        sensors.append(sensor)\n",
    "        sensor_types.append(sensor_type)\n",
    "        sensor_names.append(sensor_name)\n",
    "\n",
    "    elif \"LIDAR_\" in sensor_name:\n",
    "        blueprint_name = \"sensor.lidar.ray_cast_semantic\"\n",
    "        sensor_type = blueprint_name\n",
    "        blueprint = blueprint_library.find(blueprint_name)\n",
    "        blueprint.set_attribute(\"channels\", str(64))\n",
    "        blueprint.set_attribute(\"points_per_second\", str(112000))\n",
    "        blueprint.set_attribute(\"range\", str(100))\n",
    "        \n",
    "        transform_matrix = extrinsics.get_T_from_to(\"center\", sensor_name)\n",
    "        transform_matrix = transform_to_carla('lidar', transform_matrix)\n",
    "        transform = matrix_to_transform(transform_matrix)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "        sensors.append(sensor)\n",
    "        sensor_types.append(sensor_type)\n",
    "        sensor_names.append(sensor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of sensors spawned: {len(sensors)}\")\n",
    "print(sensor_names)\n",
    "print(sensor_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add traffic (non-ego vehicles and pedestrians) to simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vehicles_to_simulation(n_vehicles: int=0):\n",
    "    \"\"\"\n",
    "    Choos n_vehicles amount of vehicles from Carla's Blueprint Library and\n",
    "    spawn them at random points on the map. Each of those vehicles are set\n",
    "    on autopilot and controlled by Carla's Traffic Manager.\n",
    "    \n",
    "    NB! If randomly chosen spawn points collide, the vehicle is not spawned\n",
    "    so there might be fewer vehicles than set by n_vehicles.\n",
    "\n",
    "    Inputs:\n",
    "        n_vehicles - amount of vehicles to spawn\n",
    "    \"\"\"\n",
    "    if n_vehicles == 0:\n",
    "        return\n",
    "    \n",
    "    vehicle_blueprints = blueprint_library.filter('vehicle')\n",
    "    \n",
    "    npcs = []\n",
    "    collisions = 0\n",
    "    for _ in range(n_vehicles):\n",
    "        vehicle_bp = random.choice(vehicle_blueprints)\n",
    "        spawn_point = random.choice(spawn_points)\n",
    "        npc = world.try_spawn_actor(vehicle_bp, spawn_point)\n",
    "        if npc:\n",
    "            npcs.append(npc)\n",
    "        else:\n",
    "            collisions += 1\n",
    "    \n",
    "    if collisions:\n",
    "        print(f\"Failed to spawn {collisions}/{n_vehicles} vehicles because of collisions\")\n",
    "    \n",
    "    port = traffic_manager.get_port()\n",
    "    for npc in npcs:\n",
    "        npc.set_autopilot(True, port)\n",
    "\n",
    "def add_pedestrians_to_simulation(n_pedestrians: int=0,\n",
    "                                  min_speed: float=1.0,\n",
    "                                  max_speed: float=2.0) -> None:\n",
    "    \"\"\"\n",
    "    Choose n_pedestrians amount of random pedestrians from Carla's\n",
    "    Blueprint Library, attach them to AI and spawn them to random \n",
    "    positions in the simulation. Set a random location for them to \n",
    "    walk to and speed between min_speed and max_speed for them to\n",
    "    walk at.\n",
    "\n",
    "    NB! If the randomly chosen spawn points collide, a pedestrian\n",
    "    is not spawned, so there might be fewer pedestrians than \n",
    "    n_pedestrians in the simulation.\n",
    "\n",
    "    Inputs:\n",
    "        n_pedestrians - number of pedestrians to spawn\n",
    "        min_speed - minimum walking speed for a pedestrian\n",
    "        max_speed - maximum walking speed for a pedestrian\n",
    "    \"\"\"\n",
    "    if n_pedestrians == 0:\n",
    "        return\n",
    "    \n",
    "    pedestrian_blueprints = blueprint_library.filter(\"walker.pedestrian.*\")\n",
    "    points = []\n",
    "    for i in range(n_pedestrians):\n",
    "        point = carla.Transform()\n",
    "        point.location = world.get_random_location_from_navigation()\n",
    "        if (point.location != None):\n",
    "            points.append(point)\n",
    "    batch = []\n",
    "\n",
    "    # Create a batch of spawn commands\n",
    "    for point in points:\n",
    "        pedestrian_bp = random.choice(pedestrian_blueprints)\n",
    "        batch.append(carla.command.SpawnActor(pedestrian_bp, point))\n",
    "\n",
    "    # Apply the batch of commands\n",
    "    results = client.apply_batch_sync(batch, True)\n",
    "    walkers_list = []\n",
    "    collisions = 0\n",
    "    for i in range(len(results)):\n",
    "        if results[i].error:\n",
    "            collisions += 1\n",
    "        else:\n",
    "            walkers_list.append({\"id\": results[i].actor_id})\n",
    "\n",
    "    if collisions:\n",
    "        print(f\"Failed to spawn {collisions}/{n_pedestrians} pedestrians because of collisions\")\n",
    "\n",
    "    # Create a batch of spawn commands for AI controllers\n",
    "    batch = []\n",
    "    walker_controller_bp = blueprint_library.find('controller.ai.walker')\n",
    "    for i in range(len(walkers_list)):\n",
    "        batch.append(carla.command.SpawnActor(walker_controller_bp, carla.Transform(), walkers_list[i][\"id\"]))\n",
    "\n",
    "    # Apply the batch of commands\n",
    "    results = client.apply_batch_sync(batch, True)\n",
    "    for i in range(len(results)):\n",
    "        if results[i].error:\n",
    "            print(f\"Spawning pedestrian AI failed: {results[i].error}\")\n",
    "        else:\n",
    "            walkers_list[i][\"con\"] = results[i].actor_id\n",
    "\n",
    "    all_ids = []\n",
    "    for i in range(len(walkers_list)):\n",
    "        all_ids.append(walkers_list[i][\"con\"])\n",
    "        all_ids.append(walkers_list[i][\"id\"])\n",
    "    all_actors = world.get_actors(all_ids)\n",
    "\n",
    "    for i in range(0, len(all_actors), 2):\n",
    "        all_actors[i].start()\n",
    "        all_actors[i].go_to_location(world.get_random_location_from_navigation())\n",
    "        all_actors[i].set_max_speed(random.uniform(min_speed, max_speed))\n",
    "\n",
    "add_vehicles_to_simulation(n_vehicles=10)\n",
    "add_pedestrians_to_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run full simulation in CARLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filesystem methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_in_directory(target_directory):\n",
    "    if os.path.exists(target_directory):\n",
    "        for filename in os.listdir(target_directory):\n",
    "            file_path = os.path.join(target_directory, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.remove(file_path) \n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "\n",
    "\n",
    "def create_filename_from_timestamp(timestamp):\n",
    "    SECONDS_TO_NANOSECONDS = 1000000000\n",
    "    filename = str(math.trunc(timestamp * SECONDS_TO_NANOSECONDS))\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### General sensor processing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sensor_position(raw_data, target_directory, sensor_type=None):\n",
    "    transform_matrix = raw_data.transform.get_matrix()\n",
    "    if sensor_type is not None:\n",
    "        transform_matrix = transform_from_carla(sensor_type, transform_matrix)\n",
    "    if not os.path.exists(target_directory):\n",
    "        os.makedirs(target_directory, exist_ok=True)\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".npy\"\n",
    "    np.save(f\"{target_directory}/{filename}\", transform_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RBG Camera Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rgb_image(raw_data, target_directory):    \n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    rgb_image = np.reshape(np.copy(raw_data.raw_data), (raw_data.height, raw_data.width, 4))\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".png\"\n",
    "    cv2.imwrite(f\"{directory}/{filename}\", rgb_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Depth Camera Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_depth_image(raw_data, target_directory):\n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".png\"\n",
    "    raw_data.save_to_disk(f\"{directory}/{filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Semantic Camera Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_semantic_image(raw_data, target_directory):\n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".png\"\n",
    "    raw_data.save_to_disk(f\"{directory}/{filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Radar Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_radar_readings(raw_data, target_directory):\n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    radar_points_list = []\n",
    "    for measurement in raw_data:\n",
    "        azi = math.degrees(measurement.azimuth)\n",
    "        alt = math.degrees(measurement.altitude)\n",
    "        fw_vec = carla.Vector3D(x=measurement.depth)\n",
    "        carla.Transform(\n",
    "            carla.Location(),\n",
    "            carla.Rotation(pitch=alt,yaw=azi,roll=0)\n",
    "        ).transform(fw_vec)\n",
    "        radar_points_list.append([fw_vec.x, fw_vec.y, fw_vec.z])\n",
    "    \n",
    "    points = np.array(radar_points_list)\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "    \n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".ply\"\n",
    "    o3d.io.write_point_cloud(f\"{directory}/{filename}\", point_cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lidar methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_lidar(raw_data, window_name):\n",
    "    # Get the LiDAR point cloud from the data\n",
    "    lidar_data = raw_data.raw_data\n",
    "    lidar_data = np.frombuffer(lidar_data, dtype=np.dtype('f4'))\n",
    "    lidar_data = np.reshape(lidar_data, (int(lidar_data.shape[0] / 4), 4))\n",
    "\n",
    "    # Extract X, Y, Z coordinates and intensity values\n",
    "    points_xyz = lidar_data[:, :3]\n",
    "    #intensity = lidar_data[:, 3]\n",
    "\n",
    "    # Intensity scaling factor\n",
    "    intensity_scale = 2.0  # Adjust this value to control the brightness\n",
    "\n",
    "    # Create a 2D histogram with a predetermined size\n",
    "    width, height = 360, 360\n",
    "    lidar_image_array = np.zeros((height, width))\n",
    "\n",
    "    # Scale and shift X and Y coordinates to fit within the histogram size\n",
    "    def normalize(data):\n",
    "        shifted = data - np.min(data)\n",
    "        normal = shifted / np.max(shifted)\n",
    "        return normal\n",
    "    X = (normalize(points_xyz[:, 0]) * (width-1)).astype(int)\n",
    "    Y = (normalize(points_xyz[:, 1]) * (height-1)).astype(int)\n",
    "\n",
    "    # Assign scaled intensity values to the corresponding pixel in the histogram\n",
    "    lidar_image_array[Y, X] = 255\n",
    "\n",
    "    # Display the processed image using Pygame\n",
    "    cv2.imshow(window_name, lidar_image_array)\n",
    "\n",
    "def save_lidar_readings(raw_data, target_directory):\n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".ply\"\n",
    "    raw_data.save_to_disk(f\"{directory}/{filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Semantic Lidar Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_semantic_lidar_readings(semantic_lidar_data):\n",
    "    filtered_lidar_data = np.copy(semantic_lidar_data)\n",
    "    \n",
    "    unwanted_data_tags = np.array([\n",
    "        SemanticTags.ROADLINE.value, SemanticTags.ROAD.value, SemanticTags.SIDEWALK.value,\n",
    "        SemanticTags.GROUND.value, SemanticTags.WATER.value, SemanticTags.TERRAIN.value\n",
    "    ]) \n",
    "    if len(unwanted_data_tags) > 0:\n",
    "        data_tags = filtered_lidar_data[:, 3].flatten()\n",
    "        filter_mask = np.isin(data_tags, unwanted_data_tags, invert=True)\n",
    "        filtered_lidar_data = filtered_lidar_data[filter_mask]\n",
    "    \n",
    "    z_range = None\n",
    "    if z_range:\n",
    "        z_min, z_max = z_range\n",
    "        z_values = filtered_lidar_data[:, 2:3].flatten()\n",
    "        filter_mask = np.where(z_min <= z_values, True, False) * np.where(z_values <= z_max, True, False)\n",
    "        filtered_lidar_data = filtered_lidar_data[filter_mask]\n",
    "    \n",
    "    return filtered_lidar_data\n",
    "\n",
    "def save_semantic_lidar_readings(raw_data, target_directory):\n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    lidar_data = np.array([(detection.point.x, detection.point.y, detection.point.z, int(detection.object_tag)) for detection in raw_data])\n",
    "    lidar_data = filter_semantic_lidar_readings(lidar_data)\n",
    "    points = lidar_data[:, :3]\n",
    "    # Create an Open3D point cloud object\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "    # Save the point cloud to a .ply file\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".ply\"\n",
    "    o3d.io.write_point_cloud(f\"{target_directory}/{filename}\", point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMULATED_DATA_DIRECTORY = \"./generated_data\"\n",
    "delete_all_in_directory(SIMULATED_DATA_DIRECTORY)\n",
    "\n",
    "cv2.namedWindow(\"Press Q to stop simulation\")\n",
    "cv2.imshow(\"Press Q to stop simulation\", np.zeros((1,1)))\n",
    "\n",
    "agent_path = get_agent_path(planned_path)\n",
    "vehicle_control_agent.set_destination(agent_path.pop(0))\n",
    "try:\n",
    "    with CarlaSyncMode(world, sensors, fps=10) as sync_mode:\n",
    "        print(\"Driving to the start of the path...\")\n",
    "        while vehicle_control_agent.done() is False:\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "            sync_mode.tick()\n",
    "            vehicle.apply_control(vehicle_control_agent.run_step())\n",
    "        print(\"Arrived at the start of the path!\")\n",
    "\n",
    "        print(\"Driving on path...\")\n",
    "        while True:\n",
    "            simulation_results = sync_mode.tick(timeout=300.0)[1:]\n",
    "            for i in range(len(simulation_results)):\n",
    "                sensor = sensors[i]\n",
    "                sensor_data = simulation_results[i]\n",
    "                sensor_name = sensor_names[i].replace(\"base_link_to_\", \"\")\n",
    "                sensor_type = sensor_types[i]\n",
    "                if (\"camera.rgb\" in sensor_type):\n",
    "                    save_rgb_image(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "                elif (\"camera.semantic_segmentation\" in sensor_type):\n",
    "                    save_semantic_image(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "                elif (\"sensor.other.radar\" in sensor_type):\n",
    "                    save_radar_readings(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "                elif (\"camera.depth\" in sensor_type):\n",
    "                    save_depth_image(sensor_data, f\"generated_data/{sensor_name}/\") \n",
    "                elif (\"sensor.lidar.ray_cast_semantic\" in sensor_type):\n",
    "                    save_semantic_lidar_readings(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "                elif (\"sensor.lidar\" in sensor_type):\n",
    "                    save_lidar_readings(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "                save_sensor_position(sensor_data, f\"generated_data/{sensor_name}/\", sensor_type=sensor_type)\n",
    "            \n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "            if vehicle_control_agent.done():\n",
    "                print(f\"{datetime.now()} Checkpoint reached. Ego vehicle has reached {len(planned_path) - len(agent_path)}/{len(planned_path)} planned path points.\")\n",
    "                if len(agent_path) == 0:\n",
    "                    break\n",
    "                vehicle_control_agent.set_destination(agent_path.pop(0))\n",
    "            vehicle.apply_control(vehicle_control_agent.run_step())\n",
    "\n",
    "        print(\"Driving on path finished!\")\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    for sensor in sensors:\n",
    "        sensor.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
